for(value in seq(PMIN[p],PMAX[p],by=PINC[p]))
{
# Set the parameter value
PARAMETER_SET[p]<-value
# Make a column for binding to the result
PARAM_COL<-NULL
# Read in the medians file
medians<-read.csv(file.path(FILEPATH,PARAMETERS[p],value,"Medians.csv"),header=T)
for(v in 1:nrow(medians))
{
PARAM_COL<-rbind(PARAM_COL,rbind(PARAMETER_SET))
}
# Add to the global result set
result<-cbind(PARAM_COL,medians[,2:3])
ALL_RESULTS<-rbind(ALL_RESULTS,result)
}
p<-6
PARAMETER_SET<-BASELINE
for(value in seq(PMIN[p],PMAX[p],by=PINC[p]))
{
# Set the parameter value
PARAMETER_SET[p]<-value
# Make a column for binding to the result
PARAM_COL<-NULL
# Read in the medians file
medians<-read.csv(file.path(FILEPATH,PARAMETERS[p],value,"Medians.csv"),header=T)
for(v in 1:nrow(medians))
{
PARAM_COL<-rbind(PARAM_COL,rbind(PARAMETER_SET))
}
# Add to the global result set
result<-cbind(PARAM_COL,medians[,2:3])
ALL_RESULTS<-rbind(ALL_RESULTS,result)
}
nrow(results)
tail(results)
ALL_RESULTS
tail(ALL_RESULTS)
colnames(ALL_RESULTS)<-c("stableBindProbability","chemokineExpressionThreshold","initialChemokineExpressionValue","maxChemokineExpressionValue","maxProbabilityOfAdhesion","adhesionFactorExpressionSlope","Velocity","Displacement")
write.csv("/home/kja505/Documents/spartanDB/test_data/Robustness_Data.csv",quote=F,row.names=F)
write.csv(ALL_RESULTS,"/home/kja505/Documents/spartanDB/test_data/Robustness_Data.csv",quote=F,row.names=F)
parameters
parameters<-c("a")
pmin<-c(0)
pmax<-c(1)
pinc<-c(0.1)
baseline<-c(0.5)
devtools::load_all(".")
oat_parameter_sampling(NULL,parameters, baseline, PMIN=pmin, PMAX=pmax, PINC=pinc, write_csv=FALSE,return_sample=TRUE)
pmax<-c(10)
pinc<-c(10)
baseline<-c(50)
oat_parameter_sampling(NULL,parameters, baseline, PMIN=pmin, PMAX=pmax, PINC=pinc, write_csv=FALSE,return_sample=TRUE)
pmax<-c(100)
oat_parameter_sampling(NULL,parameters, baseline, PMIN=pmin, PMAX=pmax, PINC=pinc, write_csv=FALSE,return_sample=TRUE)
a<-efast_generate_sample(NULL,3,65,parameters,PMIN,PMAX,write_csv=FALSE,return_sample=TRUE)
a<-efast_generate_sample(NULL,3,65,parameters,PMIN,PMAX,write_csv=FALSE,return_sample=TRUE)
parameters
PMIN
parameters<-c("a","b")
PMIN<-c(0,1)
PMAX<-c(2,4)
a<-efast_generate_sample(NULL,3,65,parameters,PMIN,PMAX,write_csv=FALSE,return_sample=TRUE)
a
length(a)
names(a)
a
PMAX<-c(2,4,6)
PMIN<-c(0,1,1)
parameters<-c("a","b","c")
a<-efast_generate_sample(NULL,3,65,parameters,PMIN,PMAX,write_csv=FALSE,return_sample=TRUE)
a
parameters<-c("a","b","c","d")
PMIN<-c(0,1,1,1)
PMAX<-c(2,4,6,8)
a<-efast_generate_sample(NULL,3,65,parameters,PMIN,PMAX,write_csv=FALSE,return_sample=TRUE)
a
a[,,parameter,curve]
a[,,2,1]
devtools::load_all(".")
FILEPATH<-"/home/kja505/Desktop/"
parameters<-c("stableBindProbability","chemokineExpressionThreshold","initialChemokineExpressionValue","maxChemokineExpressionValue","maxProbabilityOfAdhesion","adhesionFactorExpressionSlope")
measures<-c("Velocity","Displacement")
baseline<- c(50,0.3, 0.2, 0.04, 0.60, 1.0)
minvals <- c(0, 0.10, 0.10, 0.015, 0.1, 0.25)
maxvals <- c(100, 0.9, 0.50, 0.08, 1.0, 5.0)
incvals <- c(10, 0.1, 0.05, 0.005, 0.05, 0.25)
measure_scale<-c("microns","microns/min")
oat_csv_result_file_analysis(FILEPATH, "Robustness_Data.csv", parameters, baseline, measures, "ATest_Results.csv", minvals, maxvals, incvals, PARAMVALS=NULL)
parameters<-c("stableBindProbability","chemokineExpressionThreshold","initialChemokineExpressionValue","maxChemokineExpressionValue","maxProbabilityOfAdhesion","adhesionFactorExpressionSlope")
measures<-c("Velocity","Displacement")
baseline<- c(50,0.3, 0.2, 0.04, 0.60, 1.0)
minvals <- c(10, 0.10, 0.10, 0.015, 0.1, 0.25)
maxvals <- c(100, 0.9, 0.50, 0.08, 1.0, 5.0)
incvals <- c(10, 0.1, 0.05, 0.005, 0.05, 0.25)
oat_csv_result_file_analysis(FILEPATH, "Robustness_Data.csv", parameters, baseline, measures, "ATest_Results.csv", minvals, maxvals, incvals, PARAMVALS=NULL)
parameters<-c("stableBindProbability","chemokineExpressionThreshold","initialChemokineExpressionValue","maxChemokineExpressionValue","maxProbabilityOfAdhesion","adhesionFactorExpressionSlope")
measures<-c("Velocity","Displacement")
baseline<- c(50,0.3, 0.2, 0.04, 0.60, 1.0)
minvals <- c(10, 0.10, 0.10, 0.015, 0.1, 0.25)
maxvals <- c(100, 0.9, 0.50, 0.08, 0.95, 5.0)
incvals <- c(10, 0.1, 0.05, 0.005, 0.05, 0.25)
oat_csv_result_file_analysis(FILEPATH, "Robustness_Data.csv", parameters, baseline, measures, "ATest_Results.csv", minvals, maxvals, incvals, PARAMVALS=NULL)
FILEPATH<-"/home/kja505/Desktop/eFAST"
numcurves<-3
numsamples<-65
efast_get_overall_medians(FILEPATH, 3, parameters, 65, measures)
devtools::load_all(".")
devtools::build()
PARAMOFINT<-1
PMIN<-c(0, 0.10, 0.10, 0.015, 0.1, 0.25)
PMAX<-c(100, 0.9, 0.50, 0.08, 1.0, 5.0)
PINC<-c(10, 0.1, 0.05, 0.005, 0.05, 0.25)
PARAMVALS<-NULL
# NOW GET THE LIST OF PARAMETER VALUES BEING EXPLORED FOR THIS PARAMETER
# NOTE CONVERSION BACK TO NUMBERS: GETS RID OF TRAILING ZEROS MADE BY SEQ
val_list <- as.numeric(prepare_parameter_value_list(PMIN, PMAX, PINC,
PARAMVALS,
PARAMOFINT))
val_list
BASELINE<-c(50,0.3, 0.2, 0.04, 0.60, 1.0)
# NOW GET THE LIST OF PARAMETER VALUES BEING EXPLORED FOR THIS PARAMETER
# NOTE CONVERSION BACK TO NUMBERS: GETS RID OF TRAILING ZEROS MADE BY SEQ
val_list <- as.numeric(prepare_parameter_value_list(PMIN, PMAX, PINC,
PARAMVALS,
PARAMOFINT))
PARAMETERTABLE <- generate_parameter_table(PARAMETERS, BASELINE, PARAMOFINT, val_list)
PARAMETERTABLE
all_samples[[PARAMOFINT]] <- PARAMETERTABLE
# WRITE THE A-TEST RESULTS TO FILE
results_file <- make_path(c(FILEPATH,
make_filename(c(PARAMETERS[PARAMOFINT],
"OAT_Values.csv"))))
rm(list=ls())
data("sim_data_for_emulation")
# Simulation parameters
parameters<-c("stableBindProbability","chemokineExpressionThreshold","initialChemokineExpressionValue",
"maxChemokineExpressionValue","maxProbabilityOfAdhesion","adhesionFactorExpressionSlope")
# Output measures
measures<-c("Velocity","Displacement","PatchArea")
# Mins and max values used in sampling
sampleMaxes <- cbind(100,0.9,0.5,0.08,1,5)
sampleMins <-cbind(0,0.1,0.1,0.015,0.1,0.25)
## Partition the dataset, in this case normalising the data
partitionedData <- partition_dataset(sim_data_for_emulation, parameters, percent_train=75, percent_test=15,
percent_validation=10, normalise=TRUE, sample_mins = sampleMins, sample_maxes = sampleMaxes)
getwd()
visualise_data_distribution(partitionedData$training,"Velocity","Velocity_Diagnostic")
head(sim_data_for_emulation)
visualise_data_distribution(partitionedData$training,"Velocity","Velocity_Diagnostic")
library(psych)
dataset<-partitionedData$training
measure<-"Velocity"
graphname<-"Velocity_Diagnostic"
kurt <- psych::describe(dataset[measure])
#dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
library(ggplot2)
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
ggsave(paste(graphname, ".pdf", sep = ""), device = "pdf")
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
num_bins<-30
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
dataset[measure]
ggplot(as.vector(dataset[measure]),
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
ggplot(as.vector(dataset[measure]),
aes(as.vector(dataset[measure]))) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
#dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins)
typeof(dataset[measure])
df$project<-dataset$measure
df$project<-dataset[measure]
dataset[measure]
t(dataset[measure])
dataset[measure]
dataset[,measure]
kurt <- psych::describe(dataset[measure])
ggplot(dataset[,measure],
aes(dataset[,measure])) + geom_histogram(bins=num_bins)
#dataset <- data.frame(dataset[measure])
ggplot(dataset[,measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins)
#dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins)
#dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[,measure])) + geom_histogram(bins=num_bins)
output_format=c("pdf","png")
kurt <- psych::describe(dataset[measure])
#dataset <- data.frame(dataset[measure])
ggplot(dataset[measure],
aes(dataset[,measure])) + geom_histogram(bins=num_bins)
for(out in output_format)
{
ggplot(dataset[measure],
aes(dataset[measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
ggsave(paste0(graphname, ".",out), device = out)
}
for(out in output_format)
{
ggplot(dataset[measure],
aes(dataset[,measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for ", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency")
ggsave(paste0(graphname, ".",out), device = out)
}
for(out in output_format)
{
ggplot(dataset[measure],
aes(dataset[,measure])) + geom_histogram(bins=num_bins) + ggtitle(
paste("Diagnostic Plot for", measure, "\nKurtosis:",
round(kurt$kurtosis, 3), "Skew:", round(kurt$skew, 3),
sep = " ")) +  scale_x_continuous(name = "Dataset") +
scale_y_continuous(name = "Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggsave(paste0(graphname, ".",out), device = out)
}
networkStructures<-list(c(4))
algorithmSettings<-emulation_algorithm_settings(network_structures=networkStructures)
devtools::load_all(".")
glm_fit <- generate_requested_emulations(c("GLM"),partitionedData, parameters,measures, normalised=TRUE, output_formats=c("png"))
getwd()
devtools::load_all(".")
glm_fit <- generate_requested_emulations(c("GLM"),partitionedData, parameters,measures, normalised=TRUE, output_formats=c("png"))
devtools::load_all(".")
glm_fit <- generate_requested_emulations(c("GLM"),partitionedData, parameters,measures, normalised=TRUE, output_formats=c("png"))
devtools::load_all(".")
glm_fit <- generate_requested_emulations(c("GLM"),partitionedData, parameters,measures, normalised=TRUE, output_formats=c("png"))
svm_fit <- generate_requested_emulations(c("SVM"),partitionedData, parameters,measures, normalised=TRUE, output_formats=c("png"))
predictions <- emulator_predictions(svm_fit, parameters, measures,   partitionedData$validation, normalise=FALSE, normalise_result=TRUE)
existing_simulations<-list(glm_fit,svm_fit)
generated_ensemble <- generate_ensemble_from_existing_emulations(existing_simulations,parameters, measures, partitionedData$testing,algorithm_settings=algorithmSettings, normalise=TRUE, timepoint=NULL,output_formats=c("png"))
modelList<-c("SVM","GLM")
data("sim_data_for_emulation")
# Partition the dataset (mins, maxes as declared in Technique 6)
partitionedData <- partition_dataset(sim_data_for_emulation, parameters, percent_train=75, percent_test=15,
percent_validation=10, normalise=TRUE, sample_mins = sampleMins, sample_maxes = sampleMaxes)
enerated_ensemble<-generate_emulators_and_ensemble(modelList, parameters, measures, partitionedData,
algorithm_settings = algorithmSettings, normalised=TRUE,output_formats=c("png"))
parameters <- c("stableBindProbability","chemokineExpressionThreshold",
"initialChemokineExpressionValue","maxChemokineExpressionValue",
"maxProbabilityOfAdhesion","adhesionFactorExpressionSlope")
measures<-c("Velocity","Displacement")
# Load in an ensemble generated in Technique 7, this loads in as built_ensemble
load("built_ensemble.Rda")
normalise_values = TRUE
# Whether the predictions for the parameter set should be normalised
normalise_result = TRUE
# Establish the priors for each parameter
prior=list(c("unif",0,100),c("unif",0.1,0.9),c("unif",0.1,0.5),
c("unif",0.015,0.08),c("unif",0.1,1.0),c("unif",0.25,5.0))
# Summary statistics to be targetted
sum_stat_obs=c(4.4677342593,28.5051144444)
# Create the file that will be read in by the wrapper:
create_abc_settings_object(parameters, measures, built_ensemble, normalise_values,
normalise_result)
library(EasyABC)
numRunsUnderThreshold=100
tolerance=c(20,15,10.00,7,5.00)
abc_resultSet<-ABC_sequential(method="Beaumont",
model=ensemble_abc_wrapper, prior=prior,
nb_simul=numRunsUnderThreshold,
summary_stat_target=sum_stat_obs,
tolerance_tab=tolerance, verbose=TRUE)
# Graph the result
# Ranges:
sampleMins <- c(0,0.1,0.1,0.015,0.1,0.25)
sampleMaxes<- c(100,0.9,0.5,0.08,1.0,5.0)
graph_Posteriors_All_Parameters(abc_resultSet,
parameters, sampleMins, sampleMaxes)
devtools::load_all(".")
PARAMETERS<-c("quantity","home_source_distance","initial_partition_length","alpha","epsilon","memory_factor")
MEASURES<-c("Clock", "Items", "mPartitionLength", "ExploreTime", "NestTime", "SourceTime", "WaitingTime", "ExploreRate", "NestRate", "SourceRate", "WaitingRate", "ItemsFound", "ItemsLost", "ItemsFoundRate", "ItemsLostRate")
lhc_generatePRCoEffs("~/Desktop/", PARAMETERS, MEASURES, "LHC_Summary.csv", "coeffs_out.csv")
warnings()
measures
MEASURES
PARAMETERS
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
dataset
dataset<-"/home/fgch500/robospartan/argosFiles/LHCStuff/LHCcombinedParamsAndResults.csv"
nrow(dataset)
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
parameters
parameters<-c(quantity, home_source_distance, initial_partition_length, alpha, epsilon, memory_factor)
parameters<-c("quantity", "home_source_distance", "initial_partition_length", "alpha", "epsilon", "memory_factor")
percent_train = 75
percent_test = 15
percent_validation = 10
normalise=TRUE
sample_mins<-c(2,0.5,0.2,0,0,0)
sample_maxes<-c(6,2,2,1,1,1)
devtools::load_all(".")
a<-partition_dataset(dataset,parameters,sample_mins,sample_maxes)
a<-partition_dataset(dataset,parameters,percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = TRUE, sample_mins,sample_maxes)
a
sample_mins
sample_maxes
dataset
mins <- apply(dataset, 2, min)
mins
maxs <- apply(dataset, 2, max)
maxs
# we want to override the parameter bounds with those used in sampling
mins[parameters] <- sample_mins
maxs[parameters] <- sample_maxes
mins
maxs
all.equal(c(4,4,4))
dataset
colMins
??colMins
min(dataset)
apply(data,2,min)
apply(dataset,2,min)
apply(dataset,2,min)-apply(dataset,2,max)
b<-apply(dataset,2,min)-apply(dataset,2,max)
b==0
which(b==0)
y<-which(b==0)
names(y)
b<-which((apply(dataset,2,min)-apply(dataset,2,max))==0)
b
b<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0))
b
parameters
measures
head(dataset)
dataset[, !(names(dataset) %in% b)]
dataset
dataset$WaitingRate <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA)
dataset
col_measures_all_equal<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0))
col_measures_all_equal
apply(dataset,2,is.na)
all.equal(apply(dataset,2,is.na))
apply(dataset,2,is.na)
all(is.na(apply(dataset,2,is.na))
)
all(is.na(apply(dataset,2,all(is.na))))
all(is.na(apply(dataset,2,all(is.na))))
apply(dataset,2,all(is.na))
apply(dataset,2,is.na)
all(apply(dataset,2,is.na))
apply(dataset,2,is.na)
apply(all(dataset,2,is.na))
apply(dataset,2,is.na)
all(apply(dataset,2,is.na)==TRUE)
apply(dataset,2,is.na)
apply(dataset,2,min)
col_measures_all_equal<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0 || is.na(apply(dataset,2,min)-apply(dataset,2,max))))
col_measures_all_equal
col_measures_all_equal<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0 | is.na(apply(dataset,2,min)-apply(dataset,2,max))))
col_measures_all_equal
dataset[, !(names(dataset) %in% col_measures_all_equal)]
# Now to remove those columns that are all equal from the dataset
dataset<- dataset[, !(names(dataset) %in% col_measures_all_equal)]
dataset
parameters
col_measures_all_equal
col_measures_all_equal %in% parameters
measures
measures<-c("Clock", "Items", "mPartitionLength", "ExploreTime", "NestTime", "SourceTime", "WaitingTime", "ExploreRate", "NestRate", "SourceRate", "WaitingRate", "ItemsFound", "ItemsLost", "ItemsFoundRate", "ItemsLostRate")
col_measures_all_equal %in% measures
measures<-measures[!(measures %in% col_measures_all_equal)]
measures
# Remove columns where the value is all the same, or all values are NA - these are of no use in the analysis
col_measures_all_equal<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0 | is.na(apply(dataset,2,min)-apply(dataset,2,max))))
col_measures_all_equal
length(col_measures_all_equal)
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
dataset
# Remove columns where the value is all the same, or all values are NA - these are of no use in the analysis
col_measures_all_equal<-names(which((apply(dataset,2,min)-apply(dataset,2,max))==0 | is.na(apply(dataset,2,min)-apply(dataset,2,max))))
col_measures_all_equal
length(col_measures_all_equal)
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
parameters<-c("quantity", "home_source_distance", "initial_partition_length", "alpha", "epsilon", "memory_factor")
measures<-c("Clock", "Items", "mPartitionLength", "ExploreTime", "NestTime", "SourceTime", "WaitingTime", "ExploreRate", "NestRate", "SourceRate", "WaitingRate", "ItemsFound", "ItemsLost", "ItemsFoundRate", "ItemsLostRate")
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
devtools::load_all(".")
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
partitionedData$training
devtools::load_all(".")
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
partitionedData
col_measures_all_equal
toString(col_measures_all_equal)
devtools::load_all(".")
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
devtools::load_all(".")
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
devtools::load_all(".")
dataset<-read.csv("/home/kja505/Downloads/LHC_Summary.csv",header=T)
partitionedData<-partition_dataset(dataset, parameters, measures, percent_train = 75, percent_test = 15,
percent_validation = 10, seed = NULL,
normalise = FALSE,
sample_mins = NULL, sample_maxes = NULL,
timepoint = NULL)
partitionedData
parameters != partitioned_data$parameters
partitioned_data<-partitionedData
parameters != partitioned_data$parameters
all(parameters != partitioned_data$parameters)!=FALSE
all(parameters != partitioned_data$parameters)
all(measures != partitioned_data$measures)
length(measures) != length(partitioned_data$measures)
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
devtools::load_all(".")
devtools::build()
