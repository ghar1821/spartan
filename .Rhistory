# DATA TO GRAPH RETRIEVES THE PARAMETERS,
# si AND sti TO BE GRAPHED FROM THE MAIN RESULT SET
data_to_graph <- data.frame(cbind(si[, , MEASURE], sti[, , MEASURE]),
check.names = FALSE)
MEASURE<-1
# DATA TO GRAPH RETRIEVES THE PARAMETERS,
# si AND sti TO BE GRAPHED FROM THE MAIN RESULT SET
data_to_graph <- data.frame(cbind(si[, , MEASURE], sti[, , MEASURE]),
check.names = FALSE)
# CONSTRUCT THE ERROR BAR
high_si <- data_to_graph[, 1] + errors_si[, MEASURE]
high_sti <- data_to_graph[, 2] + errors_sti[, MEASURE]
high_si
# COMBINE
errors_high <- cbind(high_si, high_sti)
errors_high
data_to_graph
colnames(data_to_graph) <- c("Si", "STi")
par(mar = c(9, 4, 4, 2) + 0.1)
gplots::barplot2(t(data_to_graph), names.arg = PARAMETERS, beside = TRUE,
main = GRAPHTITLE,
ylim = c(0, 1.0),
ylab = "eFAST Sensitivity", col = colors, xaxt = "n",
plot.ci = TRUE, ci.u = t(errors_high),
ci.l = t(data_to_graph))
labelspacing <- seq(2, (length(PARAMETERS) * 3), 3)
colors <- c("black", "grey50")
labelspacing <- seq(2, (length(PARAMETERS) * 3), 3)
gplots::barplot2(t(data_to_graph), names.arg = PARAMETERS, beside = TRUE,
main = GRAPHTITLE,
ylim = c(0, 1.0),
ylab = "eFAST Sensitivity", col = colors, xaxt = "n",
plot.ci = TRUE, ci.u = t(errors_high),
ci.l = t(data_to_graph))
data_to_graph
typeof(data_to_graph)
t(data_to_graph)
# DATA TO GRAPH RETRIEVES THE PARAMETERS,
# si AND sti TO BE GRAPHED FROM THE MAIN RESULT SET
data_to_graph <- data.frame(cbind(si[, , MEASURE], sti[, , MEASURE]),
check.names = FALSE)
typeof(data_to_graph)
load("/home/kja505/Desktop/robustness.Rda")
head(results)
PARAMETERS
PARAMETERS<-c("chemoUpperLinearAdjust","chemoLowerLinearAdjust")
BASELINE
BASELINE<-c(0.04, 0.2)
# Subset the database-mined results at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, results,
BASELINE)
baseline_result
results
baseline
BASELINE
RESULT_SET<-results
PARAMETER_VALUES_TO_FILTER_BY<-BASELINE
# TAKE A COPY OF THE RESULT SET
PARAM_RESULT <- RESULT_SET
P<-1
PARAM_RESULT <- subset(PARAM_RESULT, PARAM_RESULT[[PARAMETERS[P]]]
== as.numeric(PARAMETER_VALUES_TO_FILTER_BY[P]))
PARAM_RESULT
as.numeric(results)
results
as.numeric(BASELINE)
BASELINE
PARAM_RESULT[[PARAMETERS[P]]]
PARAMETERS[P]
PARAM_RESULT[[PARAMETERS]]
PARAM_RESULT[[PARAMETERS[1]]]
PARAM_RESULT
PARAM_RESULT<-results
PARAM_RESULT
PARAM_RESULT[[PARAMETERS[1]]]
PARAMETER_VALUES_TO_FILTER_BY
subset(PARAM_RESULT,PARAM_RESULT[[PARAMETERS[1]]]==PARAMETER_VALUES_TO_FILTER_BY[1])
load("/home/kja505/Desktop/robustness.Rda")
# Subset the database-mined results at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, results,
BASELINE)
PARAMETERS
results
PARAM_RESULT<-results
P<-1
PARAM_RESULT <- subset(PARAM_RESULT, PARAM_RESULT[[PARAMETERS[P]]]
== as.numeric(PARAMETER_VALUES_TO_FILTER_BY[P]))
PARAM_RESULT
PARAM_RESULT[[PARAMETERS[P]]]
PARAM_RESULT[PARAMETERS[P]]
PARAM_RESULT
baseline_result
baseline<-c(0.2,004)
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
result<-results
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
load("/home/kja505/Desktop/baseline.Rda")
baseline_result
nrow(baseline_result) > 0
# Do baseline A-Test - will always be no difference, but must be in
# result file for graphing
all_atest_scores <- perform_aTest_for_all_sim_measures(
BASELINE, baseline_result, baseline_result, MEASURES)
baseline_result
baseline_result_bk<-baseline_result
baseline_result<-baseline_result[1,]
# Do baseline A-Test - will always be no difference, but must be in
# result file for graphing
all_atest_scores <- perform_aTest_for_all_sim_measures(
BASELINE, baseline_result, baseline_result, MEASURES)
baseline_result[MEASURES[1]]
baseline_result[MEASURES[1]][,1]
result<-read._from_csv("/home/kja505/Downloads/Spartan_Tutorial_Data/OAT_Spartan2/CSV_Structured/OAT_Medians.csv")
result<-read_from_csv("/home/kja505/Downloads/Spartan_Tutorial_Data/OAT_Spartan2/CSV_Structured/OAT_Medians.csv")
head(result)
typeof(result)
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
baseline_result
baseline
baseline<-c(0.04,0.2)
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
baseline_result
head(result)
BASELINE<-c(0.04,0.2)
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
baseline_result
PARAMETERS
PARAMETERS<-c("chemoLowerLinearAdjust","chemoUpperLinearAdjust")
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
baseline_result
load("/home/kja505/robustness.Rda")
head(results)
# Subset the database-mined results at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, results,
BASELINE)
baseline_result
# Take the first row - incase there contains more than one response in the DB
baseline_result<-baseline_result[1,]
all_atest_scores <- perform_aTest_for_all_sim_measures(
BASELINE, baseline_result, baseline_result, MEASURES)
all_atest_scores
PARAMETERS
for (PARAM in 1:length(PARAMETERS))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
}
PARAMVALS<-NULL
for (PARAM in 1:length(PARAMETERS))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
}
PMIN<c(0.1,0.015)
PMIN<-c(0.1,0.015)
PMAX<-c(0.5,0.08)
for (PARAM in 1:length(PARAMETERS))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
}
PINC<-c(0.05,0.005)
for (PARAM in 1:length(PARAMETERS))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
}
PARAMETERS
results
PMIN
PMIN <- c(0.015, 0.10)
PMAX <- c(0.08, 0.50)
PINC <- c(0.005, 0.05)
# Now process each parameter
for (PARAM in 1:length(PARAMETERS))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
}
# label the scores
colnames(all_atest_scores) <- generate_a_test_results_header(t(PARAMETERS),MEASURES)
all_atest_scores
devtools::build()
devtools::document()
devtools::build()
db_results
results
db_results<-results
# Subset the database-mined results at baseline values
baseline_result <- subset_results_by_param_value_set(parameters, db_results,
baseline)
PARAMETERS
parameters<-PARAMETERS
baseline
# Subset the database-mined results at baseline values
baseline_result <- subset_results_by_param_value_set(parameters, db_results,
baseline)
baseline_result
(nrow(baseline_result)
)
# Take the first row - incase there contains more than one response in the DB
baseline_result<-baseline_result[1,]
baseline_result
all_atest_scores <- perform_aTest_for_all_sim_measures(
baseline, baseline_result, baseline_result, measures)
measures<-c("Velocity","Displacement")
all_atest_scores <- perform_aTest_for_all_sim_measures(
baseline, baseline_result, baseline_result, measures)
all_atest_scores
for (p in 1:length(parameters))
{
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(baseline)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, NULL, p))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, parameters, p, baseline, db_results,
exp_params, baseline_result, measures, all_atest_scores))
}
nrow(all_atest_scores)
all_atest_scores
# Take the first row - incase there contains more than one response in the DB
baseline_result<-baseline_result[1,]
all_atest_scores <- perform_aTest_for_all_sim_measures(
baseline, baseline_result, baseline_result, measures)
all_atest_scores
parameters
p<-1
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(baseline)
exp_params
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, NULL, p))
parameter_value_list
PARAM<-1
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
all_atest_scores
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
# Now iterate through the values in this list
all_atest_scores <- rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
nrow(all_atest_scores)
PARAM<-2
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
exp_params
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
rbind(all_atest_scores,
compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores))
p<-1
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(baseline)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, NULL, p))
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, parameters, p, baseline, db_results,
exp_params, baseline_result, measures, all_atest_scores)
all_atest_scores
all_atest_scores <- perform_aTest_for_all_sim_measures(
baseline, baseline_result, baseline_result, measures)
all_atest_scores
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, parameters, p, baseline, db_results,
exp_params, baseline_result, measures, all_atest_scores)
all_atest_scores
p<-2
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(baseline)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, NULL, p))
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, parameters, p, baseline, db_results,
exp_params, baseline_result, measures, all_atest_scores)
all_atest_scores
devtools::build()
results
result<-results
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
if(nrow(baseline_result) > 0)
{
# Do baseline A-Test - will always be no difference, but must be in
# result file for graphing
all_atest_scores <- perform_aTest_for_all_sim_measures(
BASELINE, baseline_result, baseline_result, MEASURES)
# Now process each parameter
for (PARAM in 1:length(PARAMETERS)) {
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
## Bug Here, fixed Sept 2018 - should not have been rbinding
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores)
#all_atest_scores <- rbind(all_atest_scores,
#                          compare_all_values_of_parameter_to_baseline (
#                            parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
#                            exp_params, baseline_result, MEASURES, all_atest_scores))
}
# label the scores
colnames(all_atest_scores) <- generate_a_test_results_header(t(PARAMETERS),MEASURES)
# Write out the result
write_data_to_csv (all_atest_scores, file.path(FILEPATH,ATESTRESULTFILENAME))
}
all_atest_scores
baseline_result
FILEPATH<-"/home/kja505/Downloads/Spartan_Tutorial_Data/OAT_Spartan2/CSV_Structured"
CSV_FILE_NAME<-"OAT_Medians.csv"
PARAMETERS
PMIN <- c(0.015, 0.10)
PMAX <- c(0.08, 0.50)
PINC <- c(0.005, 0.05)
PARAMVALS<-NULL
# Method 2:
#PARAMVALS <- c("0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06,
# 0.065, 0.07,0.075, 0.08", "0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5")
#PMIN <- NULL; PMAX <- NULL; PINC <- NULL
BASELINE <- c(0.04, 0.2)
MEASURES <- c("Velocity", "Displacement")
# What each measure represents. Used in graphing results
MEASURE_SCALE <- c("microns/min", "microns")
RESULTFILENAME <- "trackedCells_Close.csv"
OUTPUTCOLSTART <- 10
OUTPUTCOLEND <- 11
ALTERNATIVEFILENAME <- NULL
# Either 1: The name of the CSV file containing all simulation output (see description
# that follows in this section) or name to give the summary file that spartan generates
CSV_FILE_NAME <- "OAT_Medians.csv"
# Number of replicate runs performed for each parameter value set
NUMRUNSPERSAMPLE <- 300
# The results of the A-Test comparisons of each parameter value against that of the
# parameters baseline value are output as a file. This sets the name of this file.
# Current versions of spartan output this to a CSV file
ATESTRESULTSFILENAME <- "EgSet_ATests.csv"
# A-Test result value either side of 0.5 at which the difference between two sets of
# results is significant
ATESTSIGLEVEL <- 0.23
result <- read_from_csv(file.path(FILEPATH, CSV_FILE_NAME))
# Firstly filter when the simulation results were at baseline values
baseline_result <- subset_results_by_param_value_set(PARAMETERS, result,
BASELINE)
# Do baseline A-Test - will always be no difference, but must be in
# result file for graphing
all_atest_scores <- perform_aTest_for_all_sim_measures(
BASELINE, baseline_result, baseline_result, MEASURES)
for (PARAM in 1:length(PARAMETERS)) {
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
## Bug Here, fixed Sept 2018 - should not have been rbinding
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores)
#all_atest_scores <- rbind(all_atest_scores,
#                          compare_all_values_of_parameter_to_baseline (
#                            parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
#                            exp_params, baseline_result, MEASURES, all_atest_scores))
}
# label the scores
colnames(all_atest_scores) <- generate_a_test_results_header(t(PARAMETERS),MEASURES)
# Write out the result
write_data_to_csv (all_atest_scores, file.path(FILEPATH,ATESTRESULTFILENAME))
ATESTRESULTSFILENAME<-"A_Test_Scores.csv"
for (PARAM in 1:length(PARAMETERS)) {
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
## Bug Here, fixed Sept 2018 - should not have been rbinding
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores)
#all_atest_scores <- rbind(all_atest_scores,
#                          compare_all_values_of_parameter_to_baseline (
#                            parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
#                            exp_params, baseline_result, MEASURES, all_atest_scores))
}
# label the scores
colnames(all_atest_scores) <- generate_a_test_results_header(t(PARAMETERS),MEASURES)
# Write out the result
write_data_to_csv (all_atest_scores, file.path(FILEPATH,ATESTRESULTFILENAME))
ATESTRESULTFILENAME<-"A_Test_Scores.csv"
for (PARAM in 1:length(PARAMETERS)) {
# Exp_params is set as baseline, then the value of the parameter
# being analysed is adjusted, thus we have a set of parameters with
# which we can subset the result file
exp_params <- as.character(BASELINE)
# List of parameter values for this parameter
parameter_value_list <- as.numeric(
prepare_parameter_value_list(PMIN, PMAX, PINC, PARAMVALS, PARAM))
# Now iterate through the values in this list
## Bug Here, fixed Sept 2018 - should not have been rbinding
all_atest_scores <- compare_all_values_of_parameter_to_baseline (
parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
exp_params, baseline_result, MEASURES, all_atest_scores)
#all_atest_scores <- rbind(all_atest_scores,
#                          compare_all_values_of_parameter_to_baseline (
#                            parameter_value_list, PARAMETERS, PARAM, BASELINE, result,
#                            exp_params, baseline_result, MEASURES, all_atest_scores))
}
# label the scores
colnames(all_atest_scores) <- generate_a_test_results_header(t(PARAMETERS),MEASURES)
# Write out the result
write_data_to_csv (all_atest_scores, file.path(FILEPATH,ATESTRESULTFILENAME))
